import os

from transformers import GPTNeoModel, GPTNeoForCausalLM, GPT2Tokenizer, GPTNeoConfig, AutoConfig, AutoModelForCausalLM
import torch
import npu
import random

try:
	from collections.abc import MutableMapping
except ImportError:
	from collections import MutableMapping

def no_init(loading_code):
	def dummy(self):
		return

	modules = [torch.nn.Linear, torch.nn.Embedding, torch.nn.LayerNorm]
	original = {}
	for mod in modules:
		original[mod] = mod.reset_parameters
		mod.reset_parameters = dummy

	result = loading_code()
	for mod in modules:
		mod.reset_parameters = original[mod]

	return result

os.environ['CUDA_LAUNCH_BLOCKING'] = "1"

# Globals setup in functions
#gptj model in neuro is api
gptj_model = None # currently commented out in favor of neuro
#This still seems to be gptj?
model = None # CARP
tokenizer = None
skippable_tokens = []

# Globals accessed from functions
reviews = [
	"This kind of drags on.",
	"This is a bit too short.",
	"This is too cheery.",
	"This is really depressing.",
	"This is really exciting.",
	"This is boring.",
	"This ending leaves things too open.",
	"This ending feels abrupt.",
	"Could use more visual imagery.",
	"This is about bees.",
	"This story is generated by an AI.",
	"This story is weird.",
	"This would be good at show and tell."
]

carp_revision_prompt = "Rewrite Passage Based on Critique: "
gptj_revision_prompt = "Revise Passage As New Story: "
prompts = [
	{
	  "Passage": "Tom woke up in his apartment feeling tired on a rainy Saturday morning.",
	  "Critique": "Why was Tom tired?",
	  "Revision": "Rewrite Passage Based on Critique: Tom woke up in his apartment on a rainy Saturday morning, feeling tired from a late night of studying."
	},
	{
	  "Passage": "Tom woke up in his apartment feeling tired on a rainy Saturday morning.",
	  "Critique": "This is too much information at once.",
	  "Revision": "Rewrite Passage Based on Critique: Tom woke up in his apartment on a rainy Saturday morning."
	},
	{
	  "Passage": "Tom woke up in his apartment feeling tired on a rainy Saturday morning.",
	  "Critique": "Use a better adjective than tired.",
	  "Revision": "Rewrite Passage Based on Critique: Tom woke up in his apartment feeling groggy on a rainy Saturday morning."
	},
	{
	  "Passage": "Tom woke up in his apartment feeling tired on a rainy Saturday morning.",
	  "Critique": "This sentence is bland.",
	  "Revision": "Rewrite Passage Based on Critique: Tom woke to the sound of rain gently hitting his apartment window."
	},
	{
	  "Passage": "Tom woke up in his apartment feeling tired on a rainy Saturday morning.",
	  "Critique": "This sentence is boring. ",
	  "Revision": "Rewrite Passage Based on Critique: Tom woke to the sound "
	}
]

def setup_pretrained_models():
	print("Running setup_pretrained_models")
	global gptj_model
	global model
	#model = GPTNeoForCausalLM.from_pretrained(pretrained_model_name_or_path=None, config=config, state_dict=Checkpoint(checkpoint_entry="j6b_ckpt/m.pt"))
	#Why does carp seem to be using Neo?
	model = no_init(lambda: AutoModelForCausalLM.from_pretrained("EleutherAI/gpt-j-6B", revision='float16', low_cpu_mem_usage=True))
	model = model.to("cuda")

def setup_tokenizer():
	print("Running setup_tokenizer")
	global tokenizer
	tokenizer = GPT2Tokenizer.from_pretrained("EleutherAI/gpt-neo-2.7B")
	tokenizer.add_tokens(["[QUOTE]"])

def establish_skippable_strings():
	print("Running establish_skippable_strings")
	global skippable_tokens
	skippable_strings = []
	# Setting up static words to skip
	for i in range(1, 30):
		skippable_strings.append("_" * i);
	for i in range(2, 30):
		skippable_strings.append("?" * i);
	for i in range(1, 30):
		skippable_strings.append("Sam" + str(i) );
	for i in range(3, 30):
		skippable_strings.append("." + str(i) );
	skippable_strings.append("\\n")
	skippable_strings.append("\n")

	quote_idx = len(tokenizer)-1
	skippable_tokens = [18559, 59, quote_idx]
	for ss in skippable_strings:
		tokens = tokenizer(ss, add_prefix_space=True).input_ids
		for t in tokens:
			skippable_tokens.append(t)

	# Remove duplicates and wrap each element in a list
	skippable_tokens = list(dict.fromkeys(skippable_tokens))
	skippable_tokens = [ [st] for st in skippable_tokens]

def carp_critique(prompts):
	print("Running carp_critique")
	untokenized = ""
	for i in range(0, len(prompts)):
		untokenized += "Passage: " + prompts[i]["Passage"] + "\n\n"
		untokenized += "Critique: " + prompts[i]["Critique"] + "\n\n"
		#if i < len(prompts) - 1:
		#Why is this included?
		untokenized +=  prompts[i]["Revision"] + "\n\n"

	toks = tokenizer.encode_plus(untokenized, return_tensors="pt").to("cuda")

	model.config.max_length=1024
	out = model.generate(
		**toks,
		num_beams = 3,
		repetition_penalty = 1.2,
		no_repeat_ngram_size = 4,
		early_stopping = True,
		min_length = len(toks['input_ids'][0]) + 30,
		bad_words_ids = skippable_tokens,
		num_return_sequences = 3
	)

	# TODO: use this once back and forth is proven out
	#print("OUTPUT:", len(out))
	#carp_out = []
	#for i in range(0, len(out)):
	#  carp_out.append(tokenizer.decode(out[i]))
	#print(carp_out)

	carp_output = tokenizer.decode(out[0])
	return carp_output

def gptj_revise(prompts):
	print("Running gptj_revise")
	npu.api("NEURO API KEY", deployed=True)
	model_id = '60ca2a1e54f6ecb69867c72c'

	untokenized = ""
	for i in range(len(prompts) - 1, len(prompts)):
		untokenized += "Prompt: " + prompts[i]["Passage"] + "\n\n"
		untokenized += "Critique: " + prompts[i]["Critique"] + "\n\n"
		#if i < len(prompts) - 1:
		untokenized += prompts[i]["Revision"] + " "#+ "\n\n"

	tokens = tokenizer.encode_plus(untokenized, return_tensors="pt")


	kwargs = {
		'response_length': 50, # how many response tokens to generate
		'remove_input': False, # whether to return your input
		'num_beams': 4,
		'repetition_penalty': 1.2,
		'no_repeat_ngram_size': 4,
		'early_stopping': True,
		'bad_words_ids': skippable_tokens,
		'min_length': len(untokenized) + 30,
		'top_p': 0.9,
		'temperature': 0.8,
		# all params from the transformers library `generate` function are supported
	}

	gptj_output = npu.predict(model_id, [untokenized], kwargs)
	return gptj_output

def extract_carp_revision(prompts, output, carp_revision_prompt, gptj_revision_prompt, new_prompt_pos):
	print("Running extract_carp_revision")
	output = output.replace("<|endoftext|>", "")

	rev_pos = output.rfind(carp_revision_prompt) + len(carp_revision_prompt)

	if rev_pos == -1:
		print("Revision not found during carp extraction")

	revision = output[rev_pos:]
	revision = revision.replace("\n", " ")

	prompts[-1]["Passage"] = " ".join(revision.split())
	prompts[-1]["Revision"] = gptj_revision_prompt + " ".join(revision.split(" ")[:new_prompt_pos]) + " "

	return prompts

def extract_revision(revision, prompts, carp_revision_prompt, gptj_revision_prompt, new_prompt_pos):
	print("Running extract_revision")
	generated_text = revision[0]["generated_text"]
	generated_text = generated_text.replace("rompt:", "")
	#rev_pos = generated_text.rfind(gptj_revision_prompt) + len(gptj_revision_prompt)
	rev_pos = generated_text.rfind("A:") + len("A:")

	if rev_pos == -1:
		print("Revision not found during GPT-J extraction")

	new_story = generated_text[rev_pos:].replace("\n", "")

	#print("GEN:",generated_text)
	#print("ORIGINAL:",prompts[-1]["Passage"])
	#print("NEW:", new_story)

	prompts[-1]["Passage"] = new_story
	prompts[-1]["Critique"] = random.choice(reviews)
	prompts[-1]["Revision"] = carp_revision_prompt + " ".join(new_story.split(" ")[:new_prompt_pos]) + " "

	return prompts

def main():
	global prompts
	setup_pretrained_models()
	setup_tokenizer()
	#Skippable in what?
	establish_skippable_strings()

	#This is the iterative revision procedure?
	for i in range(0, 2):
		# CARP
		carp_output = carp_critique(prompts)
		prompts = extract_carp_revision(prompts, carp_output, carp_revision_prompt, gptj_revision_prompt, new_prompt_pos = 5)

		# GPT-J
		revision = gptj_revise(prompts)
		#print(revision)
		prompts = extract_revision(revision, prompts, carp_revision_prompt, gptj_revision_prompt, new_prompt_pos = 5)
		print("Iteration:", i, "Passage:", prompts[-1]["Passage"])
		print("Iteration:", i, "Critique:", prompts[-1]["Critique"])
		print("Iteration:", i, "Revision:", prompts[-1]["Revision"])

if __name__=="__main__":
	main()